---
layout:     post
title:      xgboost推导及常见问题
date:       2020-01-14
author:     wy
header-img: img/ML_BLOG/xgb-bg.jpg
catalog: true
tags:
    - 机器学习
---
## 一、知识点回顾
xgboost公式推导中用到的一些基础知识点。

### 1.1 集成学习
 **思想**：将多个机器学习模型组合起来使用，得到一个更强的模型。被组合的模型称为弱学习器，组合之后的模型称为强学习器。

 根据组合的策略不同，诞生了各种不同的算法：
     **bagging**：各个弱学习器之间没有依赖关系，如：随机森林。
     **boosting**：训练过程为阶梯状，基模型按次序一一进行训练，每轮改变训练数据权值或概率分布，如：AdaBoost，梯度提升，XGBoost。

下图为boosting算法的运行原理：
![](/img/ML_BLOG/XGB_1.png)
### 1.2 前向分布算法
> 引李航《统计学习方法》第八章，8.3.1前向分布算法。李航老师描述的前向分布算法，让我对GBDT，xgboost等这一类的boosting算法有了一个相对统一的认识。

考虑加法模型:
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

$$a + b$$